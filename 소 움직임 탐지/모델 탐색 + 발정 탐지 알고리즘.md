4. 우방 세팅이 완료된 이후 발정탐지 모델을 사용하여 인공수정 적기를 예측(수호)
   - 1년차에는 데이터 수집과 pose-estimation -> 이것도 시계열로 가능한지?
   - 그럼 소 발정 기간과 관련연구에서 데이터를 가져와서 블라블라
   - 2년차에는 활동량 데이터 앙상블 -> 시계열 데이터
   - 어떤 모델을 쓸것인지 어떤 것을 input으로 받고 
	   - hrnet / keypoint label  / rgb image
   - 발정 탐지 알고리즘 고민을 해야할 듯?

활동량은 시계열로 분석

RFID 태그 찍고 들어가는거부터 tracking
-->>> 승가 행위는 활동량과 비례하는가?
## deeplabcut - 사업체 사용 모델 

https://github.com/DeepLabCut/DeepLabCut
- 동물의 makrerless pose estimation framework
- Bottom-up 방식
- keypoint label
## OpenPose
https://github.com/CMU-Perceptual-Computing-Lab/openpose

- human 2d and 3d pose reconstruction amd estimation
## High-Resolution Net(HRNet) V

-> high resolution data
keypoint label
https://github.com/HRNet/HRNet-Human-Pose-Estimation
https://velog.io/@shshin/HRNet-%EB%85%BC%EB%AC%B8-%EC%A0%95%EB%A6%AC
- keypoint label
- W x H x 3 크기의 input 으로부터 K 개의 keypoint들을 detect하여 location을 파악
## AlphaPose(RMPE)
https://github.com/MVIG-SJTU/AlphaPose

- yolov3 backbone use
- keypoint label


- Bottom-up methods  
	우선 신체에 있는 모든 관절을 estimate한다음, 특정한 포즈 또는 하나의 사람 객체의 포즈로 그룹지어주는 방식이다.

- Top-down methods  
    사람을 먼저 detecting한 후 detecting box 안에 있는 신체 관절을 estimate한다. 문제점은 사람을 인식하지 못하면 자세 자체를 측정할 수 없고 사람의 수가 많아지면 계산량도 많아진다.