안녕하세요 이번에
Deeplabv3를 이용한 자돈사 사료 식수 탐지에 대해 발표하게 된
소프트웨어 대학원 컴퓨터공학과 한수호입니다

v
오늘 발표할 순서는 다음과 같습니다(3초 후)

v
저는 deeplabv3를 사용해서 자돈사 사료 식수 탐지를 하였는데
먼저 어떤 작업을 했는지에 대해 설명을 드리기에 앞서서
실험 환경에 대해서 간단히 설명을 드리고자 합니다.
제가 실험했던 환경은 양돈업쪽에서 자돈사라고 해서 돼지를 키우는 방이 있습니다
그 방에 그림처럼 여러개의 칸으로 나누어져있고
그 칸마다 천장에 CCTV를 Top-View로 설치를 하고 영상을 획득할 수 있는 환경에서 진행을 했습니다
그래서 실제 CCTV를 이용해서 촬영을 하면 오른쪽 사진처럼 사진이 찍히게 됩니다

v 
그래서 제가 이런 환경에서 무엇을 위해 작업을 했는지에 대해 소개를 드리자면
이렇게 돼지들이 있는 칸이 많이 있는데 사람이 직접 모든 칸을 확인하는 점검 작업을 아침에 한번 저녁에 한번 하는 상황이고 
오른쪽에 있는 사진을 보면 돼지들이 밥을 먹는 밥그릇인데 저기 설치되어 있는 장치에 이상이 생기면 사료가 안나오거나 또는 사진처럼 물이 계속해서 흘러 나오는 경우가 생깁니다.
그렇게 되면 저 물이 그냥 흘러가는게 아니라 전부 오수처리를 해야되기 때문에 비용적으로 손실이 커지게 됩니다.
그래서 저런 이상 상황을 감지하기 위해서 실험을 진행했습니다

v
그래서 semantic segmentation을 이용해서 그림에 있는것 처럼 정상상태랑 비정상인 상태를 구분하고자 하였고요 
가운데에 있는 정상 상태를 보면 빨간색이 밥그릇이고 노란색이 물이고 분홍색이 사료입니다
그래서 전체 넓이 물하고 사료의 비율을 측정해서 오른쪽 그림처럼
물의 비율이 과하게 높거나, 사료 비율이 과하게 낮은 상태를 중점적으로 탐지를 하였습니다

v 
용한 모델에 대한 설명을 하기 전에 데이터 전처리를 두가지를 했었는데 
첫번째로는 grayscale로 변환하는 작업이 있었습니다
이게 동일한 카메라여도 시간에 따라서 조명 세기가 계속해서 변하는 환경이고 색조차이가 있고
카메라도 설치된 위치에 따라서 조명이 다르고 세팅도 달라서 얻는 데이터에 불균형이 조금 있었습니다. 
그래서 grayscale로 변환을 하면 이런 부분에서 변화하는 양이 적어져서 모델의 정확도에 영향을 주었기 때문에 이러한 작업을 진행을 하였고요
v
두번째로는 이미지를 잘라서 학습을 진행을 했는데
탐지하고자 하는 대상이 전체 input 이미지 중 차지하는 비율이 되게 적은 문제가 있었습니다. 이렇게 되면 클래스 불균형이 일어나게 되어서 이미지를 오른쪽 그림처럼 잘라서 학습을 진행을 했고요
그래서 생성된 이미지 중에 배경만 있는 이미지가 있는데, 이걸 95% 확률로 제거를 했습니다.


v이렇게 했을 때 클래스 비율이 백그라운드가 87% 그다음에 나머지가 여러 정보들로 이루어져 있었는데, 오른쪽을 보시면, 배경 제거 방법을 사용했을 백그라운드가 54%로 많이 비율적으로 감소해서 모델 학습할 때 클래스 불균형을 감소시 킬 수 있었습니다.

v 실험에 사용한 모델은 저는 deeplabv3를 사용을 하였고요 deeplabv3는 
v 여기에 resnet하고 efficientnet backbone 중점적으로  사용해서 실험을 진행을 했습니다

v 다음은 실험 방법입니다.
먼저 밥그릇 위치를 탐지를 하고 이후에 그 위치를 가지고 사료와 식수를 탐지 하는 순서로 구성을 했는데요

v 왜 이렇게 했냐면 왼쪽 사진을 보면 밥그릇 위에 돼지가 있는 경우 탐지를 하면 안되는 상황입니다
탐지를 해도 오른쪽에 보이는 것처럼 가려지지 않은 부분은 괜찮은데 가려진 부분은 정상적인 값이 나오지 않기 때문인데요
이런 상황들의 탐지 결과값들을 쓸 수 없어서 돼지가 밥그릇 위에 있는 경우를 탐지해야 했습니다

v 그래서 어떻게 밥그릇 위치를 먼저 탐지를 해서 돼지가 밥그릇 위에 있는 경우를 분류를 할 수 있었냐면
자돈사 환경에서는 Top – view 고정카메라를 이용하기 때문에 움직이지 않는 물체인 밥그릇의 위치자체는 항상 일정합니다.

v 그래서 시간 간격을 두고 돼지가 있는 상황과 없는 상황에 관계없이 충분한 양을 찍고 그 사진들을 겹쳐서 일정 비율이상 겹처진 영역들을 따로 추출하게 됩니다

v 그래서 model의 segmenation map과 아래에 있는 미리 찾은 밥그릇 위치를 비교해서
일정 비율 이상 겹치게 되면 밥그릇 위치에 있는 데이터만 사용을 하고

v 지금 그림처럼 일정한 비율 이상 겹치지 않는 경우에는 노이즈가 있다고 판단을 해서 데이터 사용을 안하게 됩니다

모델들로 각각 train dataset 500개 50 epoch로 실험했을때 miou값은 이렇게 나왔고요
모델은 fcn,unet을 가지고도 실험을 했었는데 deeplabv3에 비해서 정확도가 그렇게 높게 나오지않아서 deeplabv3만 사용을 했었고요 그리고  deeplabv3에서 백본들을 바꿔보면서 실험 했을때의 miou값이 다음과 같이 resnet101 backbone을 사용한 경우 가장 높게 나오는것을 확인할 수 있었습니다

향후 개선 방안입니다
이미지의 부족으로 인한 오버피팅 문제가 있었는데
데이터 자체도 수집을 더 해야할 것 같고요
그 다음에 좀 기본적인 Image augmentation 기법들만 적용을 했는데
여러가지 augmentation 방법을 
그리고 resnet같은 경우에는 모델을 더 깊게 쌓았을때가 모델 성능이 높았는데
Efficientnet 같은 경우에는 그렇지 않아서 그 부분에 대한 분석이 필요한 상황입니다.
