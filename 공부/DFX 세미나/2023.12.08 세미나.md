# NLP With Mobile

## ML Kit


## Pytorch Demo

예제에서는 프랑스 to 영어
한국어 to 영어의 경우 조사 어미같은 부분을 토큰으로 분류하여 
예제에 비해 토큰의 양이 증가함

## MediaSoup
-> 기존 wep rtc로 구현해야하는것을 간편하게 도와줌
화상회의 플렛폼


# 딥러닝 모델 연산속도 최적화

## 연산속도 최적화 방안
- 병렬 프로세싱
- GPGPU 사용
- Model 사이즈 축소
- input 사이즈 축소
- 특정 로직 알고리즘 수행 속도 개선
- 딥러닝 모델의 inference 속도 개선
	- OpenCL,CUDA가 핵삼

## OpenCL 소개
제한된 시간 안에 무언가 개발하기엔 좀 무겁다?
디바이스 별로 다른 프로그래밍 방법이 존재 -> 하나로 묶어서 개발하겠다(자바처럼?)
CPU,GPU,FPGA등등에서 동작

- 한계점
	- 성능 이식성의 부재(타깃 디바이스에 따라 최적화가 별도로 필요)
	- 단일 OS내의 장치만 프로그래밍 가능

## 실제 최적화 사례
- TensorRT openVino등을 이용해서 모델 경량화 함
	- 양자화가 대부분
- input size 감소 or 양자화
